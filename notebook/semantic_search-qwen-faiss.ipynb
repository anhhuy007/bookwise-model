{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-02T15:54:20.071007Z",
     "iopub.status.busy": "2025-01-02T15:54:20.070691Z",
     "iopub.status.idle": "2025-01-02T15:54:26.257512Z",
     "shell.execute_reply": "2025-01-02T15:54:26.256441Z",
     "shell.execute_reply.started": "2025-01-02T15:54:20.070975Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu, sentence-transformers\n",
      "Successfully installed faiss-cpu-1.9.0.post1 sentence-transformers-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install sentence-transformers transformers faiss-cpu pandas datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:54:26.258932Z",
     "iopub.status.busy": "2025-01-02T15:54:26.258610Z",
     "iopub.status.idle": "2025-01-02T15:54:36.800097Z",
     "shell.execute_reply": "2025-01-02T15:54:36.799318Z",
     "shell.execute_reply.started": "2025-01-02T15:54:26.258907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import faiss\n",
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:54:36.801242Z",
     "iopub.status.busy": "2025-01-02T15:54:36.800777Z",
     "iopub.status.idle": "2025-01-02T15:54:36.847961Z",
     "shell.execute_reply": "2025-01-02T15:54:36.846839Z",
     "shell.execute_reply.started": "2025-01-02T15:54:36.801220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clear_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Add after each generation\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:54:36.850062Z",
     "iopub.status.busy": "2025-01-02T15:54:36.849820Z",
     "iopub.status.idle": "2025-01-02T15:54:38.798960Z",
     "shell.execute_reply": "2025-01-02T15:54:38.798252Z",
     "shell.execute_reply.started": "2025-01-02T15:54:36.850041Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99abbbf2f2e14662af19bcecc7873aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "book-data.csv:   0%|          | 0.00/572k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b5725677eb44c8ad490fa1db9c4a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/497 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Load the Dataset from Hugging Face ---\n",
    "dataset = load_dataset(\"matoupines/book-dataset\")\n",
    "train_data = dataset['train'].to_pandas()  # Convert dataset to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:54:38.800379Z",
     "iopub.status.busy": "2025-01-02T15:54:38.800158Z",
     "iopub.status.idle": "2025-01-02T15:54:38.805490Z",
     "shell.execute_reply": "2025-01-02T15:54:38.804629Z",
     "shell.execute_reply.started": "2025-01-02T15:54:38.800361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Data Cleaning and Formatting ---\n",
    "def clean_text(text):\n",
    "    \"\"\"Cleans text by removing/replacing special characters.\"\"\"\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return \"\"\n",
    "    text = str(text)  # Ensure text is a string\n",
    "    text = text.strip()  # Remove leading/trailing whitespace\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single spaces\n",
    "    return text\n",
    "\n",
    "def format_authors(authors):\n",
    "    \"\"\"Formats the authors field to ensure proper quoting for multiple authors.\"\"\"\n",
    "    if pd.isna(authors):\n",
    "        return \"\"\n",
    "    authors = str(authors)\n",
    "    # If there's a comma, assume multiple authors and enclose in quotes\n",
    "    if ',' in authors:\n",
    "        return f'\"{authors}\"'\n",
    "    else:\n",
    "        return authors  # Return as is if no comma (single author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:54:38.806770Z",
     "iopub.status.busy": "2025-01-02T15:54:38.806450Z",
     "iopub.status.idle": "2025-01-02T15:54:38.859164Z",
     "shell.execute_reply": "2025-01-02T15:54:38.858567Z",
     "shell.execute_reply.started": "2025-01-02T15:54:38.806722Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Apply cleaning functions to relevant fields\n",
    "train_data['title'] = train_data['title'].apply(clean_text)\n",
    "train_data['description'] = train_data['description'].apply(clean_text)\n",
    "train_data['authors'] = train_data['authors'].apply(format_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:54:38.860051Z",
     "iopub.status.busy": "2025-01-02T15:54:38.859865Z",
     "iopub.status.idle": "2025-01-02T15:54:38.865088Z",
     "shell.execute_reply": "2025-01-02T15:54:38.864382Z",
     "shell.execute_reply.started": "2025-01-02T15:54:38.860034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Combine Fields for Embedding ---\n",
    "train_data[\"text\"] = train_data[\"title\"] + \" \" + train_data[\"authors\"] + \" \" + train_data[\"description\"]\n",
    "documents = train_data[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:54:38.866034Z",
     "iopub.status.busy": "2025-01-02T15:54:38.865747Z",
     "iopub.status.idle": "2025-01-02T15:54:38.897186Z",
     "shell.execute_reply": "2025-01-02T15:54:38.896294Z",
     "shell.execute_reply.started": "2025-01-02T15:54:38.866007Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6ca0bda663457884fc7e47259e4cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:54:38.898281Z",
     "iopub.status.busy": "2025-01-02T15:54:38.898022Z",
     "iopub.status.idle": "2025-01-02T15:57:20.866324Z",
     "shell.execute_reply": "2025-01-02T15:57:20.865357Z",
     "shell.execute_reply.started": "2025-01-02T15:54:38.898260Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1256318d0c24b9db6386581a3f31bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ad9d0f045249c5a1a12e6a1f380daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2553ec49dc4ea0a5c539b31fa9589b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f5b22f65d247618a800b43ffa49ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c0a47875804e0580bdf6f8fb12f91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defdf6accb5e49a1ba9d16216b4a65c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed691ff8e8114e718d7a007f05617f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311bf9340c304637a1c24c78bc5d01af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff01f323099f4c6e882ab844f678f6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026503bb278e4f668eb494b07ebb8330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eee766eca43449abc41a9606bfc4f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b77898217f444d7aaf6fecd34bc196a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0600c93e835740a0863d6389ca128fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fff0509e2d440f9b1a3a0be8ffd3937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a37e757c0a487eadd50909ff58443f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc99f8bde4ce442b9a2163b26aae3a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed67fa16ba834c8fb8bc012ff2e53bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/683 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30ec927dc8246108a315e1578a5e8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408a2deea6be4bed9d8694a137a7b6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cb8638b0b64588a38f834a2fc3a496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/3.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf48273769f413288605c1364c563f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84adcf7fb8f8499f9f3dea3ad841c76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11749de931f04afcad40b3f23cf8d4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Initialize Embedding Model ---\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate Embeddings for the Dataset\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = embedding_model.encode(documents, show_progress_bar=True)\n",
    "\n",
    "# Convert embeddings to float32 for FAISS\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "# --- Initialize FAISS ---\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Cosine similarity\n",
    "embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)  # Normalize embeddings\n",
    "index.add(embeddings)  # Add normalized embeddings to FAISS index\n",
    "\n",
    "# Save FAISS index (optional)\n",
    "faiss.write_index(index, \"books_index.faiss\")\n",
    "print(\"FAISS index saved.\")\n",
    "\n",
    "# Load Qwen-2.5 tokenizer and model\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B\")\n",
    "qwen_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:57:20.867893Z",
     "iopub.status.busy": "2025-01-02T15:57:20.867514Z",
     "iopub.status.idle": "2025-01-02T15:57:21.722634Z",
     "shell.execute_reply": "2025-01-02T15:57:21.721941Z",
     "shell.execute_reply.started": "2025-01-02T15:57:20.867858Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T15:57:21.723955Z",
     "iopub.status.busy": "2025-01-02T15:57:21.723597Z",
     "iopub.status.idle": "2025-01-02T15:57:22.958658Z",
     "shell.execute_reply": "2025-01-02T15:57:22.957852Z",
     "shell.execute_reply.started": "2025-01-02T15:57:21.723921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def truncate_context(query, context, max_input_tokens):\n",
    "    \"\"\"Truncate context to fit within model's token limit.\"\"\"\n",
    "    # Start with smaller context chunks\n",
    "    context_chunks = context.split('\\n')\n",
    "    truncated_chunks = []\n",
    "    current_text = f\"Query: {query}\\nContext:\"\n",
    "    \n",
    "    for chunk in context_chunks:\n",
    "        test_text = current_text + f\"\\n{chunk}\\nAnswer:\"\n",
    "        tokens = qwen_tokenizer(test_text, return_tensors=\"pt\", truncation=True, max_length=max_input_tokens)\n",
    "        \n",
    "        if len(tokens[\"input_ids\"][0]) < max_input_tokens:\n",
    "            truncated_chunks.append(chunk)\n",
    "            current_text = f\"Query: {query}\\nContext: {' '.join(truncated_chunks)}\"\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return current_text + \"\\nAnswer:\"\n",
    "\n",
    "def generate_response(query, context, max_new_tokens=150):\n",
    "    \"\"\"Generate a factually accurate response using a more structured and restrictive prompt.\"\"\"\n",
    "    max_input_tokens = min(2048, qwen_tokenizer.model_max_length - max_new_tokens)\n",
    "    \n",
    "    prompt = f\"\"\"You are a helpful assistant that provides factually accurate and relevant responses.\n",
    "    Your answers should be based strictly on the given context, and you should aim for clarity and precision.\n",
    "    Do not invent information or provide guesses. If the context doesn't provide an answer, simply say you don't know.\n",
    "    Ensure that your answer directly addresses the user's query.\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {query}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = qwen_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_input_tokens)\n",
    "    \n",
    "    outputs = qwen_model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=qwen_tokenizer.eos_token_id,\n",
    "        temperature=0.2,  # Lower for more deterministic and precise outputs\n",
    "        top_p=0.85,       # Slightly narrower sampling pool for better quality\n",
    "        repetition_penalty=2.0,  # Increased penalty for repetition to reduce redundancy\n",
    "        no_repeat_ngram_size=4,  # Larger n-gram size to avoid repetitive phrases\n",
    "        length_penalty=1.2,      # Slight penalty to avoid overly long answers\n",
    "        early_stopping=True      # Stop generation early if the answer is complete\n",
    "    )\n",
    "    \n",
    "    # Decode and clean up the output\n",
    "    response = qwen_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "def get_relevant_docs(query, k=5):\n",
    "    \"\"\"Retrieve relevant documents with semantic search.\"\"\"\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    distances, indices = index.search(query_embedding.astype(\"float32\"), k)\n",
    "    \n",
    "    # Convert to DataFrame and sort by relevance\n",
    "    df = pd.DataFrame(dataset['train'])\n",
    "    results = df.iloc[indices[0]]\n",
    "    \n",
    "    # Only return highly relevant results\n",
    "    mask = distances[0] < 1.2  # Adjust threshold as needed\n",
    "    return results[mask], distances[0][mask]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T16:06:03.835825Z",
     "iopub.status.busy": "2025-01-02T16:06:03.835447Z",
     "iopub.status.idle": "2025-01-02T16:06:03.841404Z",
     "shell.execute_reply": "2025-01-02T16:06:03.840633Z",
     "shell.execute_reply.started": "2025-01-02T16:06:03.835796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def summarize_context(relevant_docs, max_tokens=500):\n",
    "    # Summarize the context to limit the number of tokens\n",
    "    summarized_context = \"\"\n",
    "    token_count = 0\n",
    "\n",
    "    for _, row in relevant_docs.iterrows():\n",
    "        context_piece = f\"Title: {row['title']}, Description: {row['description']}\\n\"\n",
    "        tokenized_piece = qwen_tokenizer(context_piece)[\"input_ids\"]\n",
    "        \n",
    "        # Check if adding this piece would exceed the token limit\n",
    "        if token_count + len(tokenized_piece) <= max_tokens:\n",
    "            summarized_context += context_piece\n",
    "            token_count += len(tokenized_piece)\n",
    "        else:\n",
    "            break  # Stop adding more context if we exceed token limit\n",
    "\n",
    "    return summarized_context\n",
    "\n",
    "def generate_optimized_response(query, relevant_docs, max_new_tokens=150, max_tokens=500):\n",
    "    # Prepare the context by summarizing or truncating it\n",
    "    context = summarize_context(relevant_docs, max_tokens)\n",
    "    \n",
    "    # Prepare the prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant. Please provide a summary of the book titled \"Twenty Wishes\" by Debbie Macomber, based solely on the context below:\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Please ensure the summary accurately reflects the plot of *Twenty Wishes* and does not include unrelated information from other books. \n",
    "    Do not invent any details or provide guesses. Summarize the main story of the book clearly and concisely.\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # Check tokenized length\n",
    "    tokenized_length = len(qwen_tokenizer(prompt)[\"input_ids\"])\n",
    "    print(f\"Tokenized input length before truncation: {tokenized_length} tokens\")\n",
    "\n",
    "    # Generate response\n",
    "    response = generate_response(query, context, max_new_tokens)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-02T16:16:45.393786Z",
     "iopub.status.busy": "2025-01-02T16:16:45.393407Z",
     "iopub.status.idle": "2025-01-02T16:16:45.470763Z",
     "shell.execute_reply": "2025-01-02T16:16:45.470112Z",
     "shell.execute_reply.started": "2025-01-02T16:16:45.393759Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find some books that similar to the book the tipping point of malcolm gladwell\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bc334b81bb4d8ab0fc33b795c1fd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What the Dog Saw by Malcolm Gladwell\n",
      "Title: The Secret by Rhonda Byrne\n",
      "Title: Outliers by Malcolm Gladwell\n",
      "Title: Dear Martin by Nic Stone\n",
      "Title: The Pocket Dangerous Book for Boys: Things to Do by \"Conn Iggulden, Hal Iggulden\"\n"
     ]
    }
   ],
   "source": [
    "# Example usage with your query\n",
    "query = \"Find some books that similar to the book the tipping point of malcolm gladwell\"\n",
    "print(query)\n",
    "\n",
    "relevant_docs, scores = get_relevant_docs(query, 5)\n",
    "recommended_books = \"\\n\".join(\n",
    "    [\n",
    "        f\"Title: {row['title']} by {row['authors']}\"\n",
    "        for _, row in relevant_docs.iterrows()\n",
    "    ]\n",
    ")\n",
    "print(recommended_books)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
